<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on Sun longyu</title>
    <link>https://sunlongyu.github.io/blogs/</link>
    <description>Recent content in Blogs on Sun longyu</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 01 Feb 2025 04:55:54 +0530</lastBuildDate>
    <atom:link href="https://sunlongyu.github.io/blogs/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM Pre-Training</title>
      <link>https://sunlongyu.github.io/blogs/llm-pre-training/</link>
      <pubDate>Sat, 01 Feb 2025 04:55:54 +0530</pubDate>
      <guid>https://sunlongyu.github.io/blogs/llm-pre-training/</guid>
      <description>&lt;h1 id=&#34;预训练---研发大语言模型的第一个训练阶段&#34;&gt;预训练 - 研发大语言模型的第一个训练阶段&lt;/h1&gt;&#xA;&lt;p&gt;预训练是研发大语言模型的第一个训练阶段，通过在大规模语料上进行预训练，大语言模型可以获得通用的语言理解与生成能力，掌握较为广泛的世界知识，具备解决众多下游任务的性能潜力。&lt;/p&gt;&#xA;&lt;h2 id=&#34;一数据预处理&#34;&gt;一、数据预处理&lt;/h2&gt;&#xA;&lt;h3 id=&#34;一数据的收集&#34;&gt;（一）数据的收集&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;通用文本数据（“主食”）&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：网页（C4 、RefinedWeb、CC-Stories 等）；书籍（Books3 、Bookcorpus2 等）。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt; ：量大；多样；需要清洗；注意搭配。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;专用文本数据（“特色”）&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;多语言文本&lt;/strong&gt; ：加入大量非英语的文本数据，加强多语言任务的同时，还能促进不同语言的知识迁移，提升模型泛化能力（BLOOM 和 PaLM 模型使用了百种语言进行训练）。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;科学文本&lt;/strong&gt; ：加入大量科学文献、论文（比如 ArXiv 数据集）、教科书等，提升模型在专业领域的问答、推理和信息抽取能力（注意公式等符号需要采用特定的分词和预处理技术）。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;代码&lt;/strong&gt; ：加入海量来自 Stack Exchange、GitHub 等的代码数据，提升编程能力。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;二数据预处理&#34;&gt;（二）数据预处理&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;质量过滤 - 去除低质量&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;基于启发式规则&lt;/strong&gt; ：以精心设计的规则（基于语种、统计指标、关键词）识别和剔除低质量文本。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;基于分类器&lt;/strong&gt; ：用人工标注的高质量和低质量数据训练模型来判断文本质量，实现方法包括轻量级模型（如 FastText）、可微调的预训练语言模型（如 BERT、BART 或者 LLaMA 等）以及闭源大语言模型 API（如 GPT - 4）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;敏感内容过滤 - 去除敏感&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;有毒内容&lt;/strong&gt; ：采用基于分类器的过滤方法（Jigsaw 评论数据集可用于训练毒性分类器），通过设置合理的分类阈值，识别并过滤掉有毒内容。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;隐私内容&lt;/strong&gt; ：使用启发式方法（关键字识别）检测和删除私人信息。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;去重&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;基于计算粒度&lt;/strong&gt; ：在句子级别、文档级别和数据集级别等多种粒度上进行去重，采用多阶段、多粒度的方式实现高效去重。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;基于匹配算法&lt;/strong&gt; ：文档层面使用开销较小的近似匹配（局部敏感哈希：minhash），句子层面使用精确匹配算法（后缀数组匹配最小长度的完全相同子串）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;数据词元化（Tokenization）&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;BPE&lt;/strong&gt; ：统计文本里最常相邻出现的组合，不断合并，直到达到预设的词库大小；字节级 BPE 可表示任何字符。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;WordPiece&lt;/strong&gt; ：选择能让整个文本可能性提升最大的词元对合并，合并前会训练语言模型对词元对进行评分。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Unigram&lt;/strong&gt; ：从初始集合开始，迭代删除词元，采用期望最大化 EM 算法，逐步缩减零件库直到目标大小。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;分词器 Tokenizer&lt;/strong&gt; ：对于混合多领域多种格式的语料，制定具备无损重构、高压缩率、高适应性的分词器。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;流行的分词库 SentencePiece&lt;/strong&gt; ：Google 开源的库，支持 BPE 和 Unigram，很多大模型用它定制分词器。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;三数据调度-data-scheduling&#34;&gt;（三）数据调度 Data Scheduling&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;数据混合配比&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM入门</title>
      <link>https://sunlongyu.github.io/blogs/llm%E5%85%A5%E9%97%A8/</link>
      <pubDate>Tue, 14 Jan 2025 07:07:07 +0100</pubDate>
      <guid>https://sunlongyu.github.io/blogs/llm%E5%85%A5%E9%97%A8/</guid>
      <description>&lt;h1 id=&#34;一大模型概述&#34;&gt;一、大模型概述&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1大模型概念&#34;&gt;1、大模型概念&lt;/h2&gt;&#xA;&lt;p&gt;LLM 是指用有大量参数的大型预训练语言模型，在解决各种自然语言处理任务方面表现出强大的能力，甚至可以展现出一些小规模语言模型所不具备的特殊能力。&lt;/p&gt;&#xA;&lt;h2 id=&#34;2语言模型-language-model&#34;&gt;2、语言模型 language model&lt;/h2&gt;&#xA;&lt;p&gt;语言建模旨在对词序列的生成概率进行建模，以预测未来 tokens 的概率，语言模型的发展：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;统计语言模型 SLM&lt;/strong&gt; ：统计语言模型使用马尔可夫假设（Markov Assumption）来建立语言序列的预测模型，通常是根据词序列中若干个连续的上下文单词来预测下一个词的出现概率，经典的例子是 n - gram 模型，在此模型中一个词出现的概率只依赖于前面的 n - 1 个词，比如一个 3gram 模型只考虑前两个词对第三个词出现概率的影响。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;神经语言模型 NLM&lt;/strong&gt; ：使用神经网络来预测词序列的概率分布，如 RNN 包括 LSTM 和 GRU 等变体，这样 NLM 就可以考虑更长的上下文或整个句子的信息，而传统的统计语言模型使用固定窗口大小的词来预测；在该模型中引入分布式词表示，每个单词被编码为实数值向量，即词嵌入（word embeddings）用来捕捉词与词之间的语法关系。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;预训练语言模型 PLM&lt;/strong&gt; ：PLM 开始在规模无标签语料库上进行预训练任务，学习语言规律知识，并且针对特定任务进行微调（fine - tuning）来适应不同应用场景；而对于大规模的长文本，谷歌提出了 transformer，通过自注意力机制（self - attention）和高度并行化能力，可以在处理序列数据时捕捉全局依赖关系，极大提高序列处理任务的效率。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;大语言模型 LLM&lt;/strong&gt; ：当一些研究工作尝试训练更大的预训练语言模型（例如 175B 参数的 GPT - 3 和 540B 参数的 PaLM）来探索扩展语言模型所带来的性能极限。这些大规模的预训练语言模型在解决复杂任务时表现出了与小型预训练语言模型（如 330M 参数的 BERT 和 1.5B 参数的 GPT2）不同的行为，这种大模型具有但小模型不具备的能力通常被称为 “涌现能力”（Emergent Abilities），这些大型的预训练模型就是 LLM。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;3大模型特点&#34;&gt;3、大模型特点&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;参数数量庞大，数据需求巨大&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;计算资源密集&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;泛化能力强&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;迁移学习效果佳&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;4小模型-vs-大模型&#34;&gt;4、小模型 vs 大模型&lt;/h2&gt;&#xA;&lt;h2 id=&#34;5大模型企业应用&#34;&gt;5、大模型企业应用&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;通用大模型&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;行业大模型&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;产业大模型&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;二大模型基础&#34;&gt;二、大模型基础&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1大模型构建过程&#34;&gt;1、大模型构建过程&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1大规模预训练large---scale-pre---training&#34;&gt;（1）大规模预训练（Large - Scale Pre - training）&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;目标&lt;/strong&gt; ：为模型参数找到好的 “初值点”，使其编码世界知识，具备通用的语言理解和生成能力。可以看作是世界知识的压缩。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;方法&lt;/strong&gt; ：使用海量（当前普遍 2 - 3T tokens 规模，并有扩大趋势）的无标注文本数据，通过自监督学习任务（当前主流是 “预测下一个词”）训练解码器架构（Decoder Architecture）模型。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;关键要素&lt;/strong&gt; ：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;数据&lt;/strong&gt; ：高质量、多源化数据的收集与严格清洗至关重要，直接影响模型能力。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;算力&lt;/strong&gt; ：需求极高（百亿模型需数百卡，千亿模型需数千甚至万卡集群），训练时间长。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;技术与人才&lt;/strong&gt; ：涉及大量经验性技术（数据配比、学习率调整、异常检测等），高度依赖研发人员的经验和能力。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2指令微调与人类对齐instruction-fine---tuning--human-alignment&#34;&gt;（2）指令微调与人类对齐（Instruction Fine - tuning &amp;amp; Human Alignment）&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;动机&lt;/strong&gt; ：预训练模型虽有知识，但不擅长直接按指令解决任务。需要进一步训练以适应人类的使用方式和价值观。&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM开发之RAG</title>
      <link>https://sunlongyu.github.io/blogs/llm%E5%BC%80%E5%8F%91%E4%B9%8Brag/</link>
      <pubDate>Sun, 15 Dec 2024 12:00:00 +0800</pubDate>
      <guid>https://sunlongyu.github.io/blogs/llm%E5%BC%80%E5%8F%91%E4%B9%8Brag/</guid>
      <description>&lt;h1 id=&#34;一rag-概述&#34;&gt;一、RAG 概述&lt;/h1&gt;&#xA;&lt;h2 id=&#34;一llm-的缺陷&#34;&gt;（一）LLM 的缺陷&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;幻觉&lt;/strong&gt; ：LLM 可能生成无事实依据、不与现实世界一致，甚至完全虚构的内容。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;知识更新滞后&lt;/strong&gt; ：LLM 知识的有效性取决于训练数据的时间，存在知识更新滞后问题。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;回答缺乏透明度&lt;/strong&gt; ：LLM 生成的回答通常缺乏引用来源，导致用户难以判断答案的真实性，降低模型可信度。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;二definition&#34;&gt;（二）Definition&lt;/h2&gt;&#xA;&lt;p&gt;为缓解上述问题，RAG 通过检索外部知识库相关信息，并将信息作为上下文输入语言模型，增强生成能力，减少幻觉、提供事实依据，借外部知识库实现实时更新，使生成结果带检索来源，提升专业领域表现。&lt;/p&gt;&#xA;&lt;h2 id=&#34;三组件&#34;&gt;（三）组件&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;向量数据库 (Vector DB)&lt;/strong&gt; ：存储和检索嵌入向量，如 FAISS、Pinecone、Weaviate。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;嵌入模型 (Embedding Model)&lt;/strong&gt; ：将文本转换为向量，如 OpenAI Embeddings、BERT。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;检索模型 (Retriever)&lt;/strong&gt; ：检索相关信息，可使用 BM25、Dense Retrieval (DPR) 等方法。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;LLM (Large Language Model)&lt;/strong&gt; ：如 GPT - 4 等，负责生成最终答案。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;融合策略 (Fusion Strategy)&lt;/strong&gt; ：结合检索信息与 LLM 结果，提高生成可信度。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;四常见应用领域&#34;&gt;（四）常见应用领域&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;企业知识问答&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;法律 / 医疗领域问答&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;金融风控&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;搜索增强对话&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;二rag-实现&#34;&gt;二、RAG 实现&lt;/h1&gt;&#xA;&lt;h2 id=&#34;一数据处理&#34;&gt;（一）数据处理&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-数据清洗-cleaning&#34;&gt;1. 数据清洗 cleaning&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;去重 (Deduplication)&lt;/strong&gt; ：去除重复文档或内容，提高存储效率，减少无效检索。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;噪声过滤 (Noise Filtering)&lt;/strong&gt; ：删除无关内容、广告、低质量文本，避免干扰 LLM 生成。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;格式标准化 (Normalization)&lt;/strong&gt; ：统一文本编码、标点符号、日期格式，保证数据一致性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-数据分片-chunking&#34;&gt;2. 数据分片 chunking&lt;/h3&gt;&#xA;&lt;h4 id=&#34;基于规则的-chunking&#34;&gt;基于规则的 chunking&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;固定长度分片&lt;/strong&gt; ：按固定字符数或单词数切分，如每 512 词分为一个 Chunk。适合结构化文本（如 Wikipedia），但可能导致句子或段落拆散，影响语义完整性。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;基于段落的 Chunking&lt;/strong&gt; ：以自然语言逻辑单元（如句子、段落）进行分片，保持上下文完整性。适用于法律、医学文档，但 Chunk 长度不均匀，可能影响索引效率。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;滑动窗口分片&lt;/strong&gt; ：相邻 Chunk 之间有部分重叠，如窗口大小 256 词，滑动步长 128 词。可保证跨段落上下文信息，减少查询时信息丢失，但增加存储和计算开销。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;基于模型的-chunking&#34;&gt;基于模型的 chunking&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Transformer 句子分割&lt;/strong&gt; ：用 Transformer 模型（如 BERT、RoBERTa）检测句子边界，以高语义相关性进行分片。适用于复杂文档（如法律、医学文本），避免破坏逻辑结构。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;基于依存关系的 Chunking&lt;/strong&gt; ：依存句法分析识别主谓宾结构，以语法结构为基础拆分 Chunk。适用于技术文档（如 API 说明书、论文摘要）。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;基于 LLM 的 Chunking&lt;/strong&gt; ：让 LLM 自适应判断 Chunk 切分点，根据上下文哪些部分应作为独立片段。适用于非结构化文本（如用户评论、社交媒体内容）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;small2big-chunking&#34;&gt;Small2Big Chunking&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;核心思想&lt;/strong&gt; ：先生成较小 Chunk，再按语义相似度合并成较大 Chunk，形成合理文档分片结构，结合固定长度切分与语义分析，避免传统 Chunking 方法弊端。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;初步切分小片段 (Small Chunks)&lt;/strong&gt; ：用固定长度或自然段落切分，保持文本语义完整性。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;计算 Chunk 之间语义相似度&lt;/strong&gt; ：用 BERT/SBERT 向量嵌入将 Chunk 表示为向量；计算相邻 Chunk 余弦相似度 S_{i,i+1}；设相似度阈值 \tau ，若 S_{i,i+1} &amp;gt; \tau 则合并。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;相似度高的 Chunk 合并&lt;/strong&gt; ：形成更大、更有信息密度的片段，逐步执行直至不满足合并条件。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;存入向量数据库&lt;/strong&gt; ：采用 FAISS/Pinecone 存储优化后的 Chunk。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-数据嵌入-embedding&#34;&gt;3. 数据嵌入 embedding&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;嵌入模型选择&lt;/strong&gt; ：&lt;/p&gt;</description>
    </item>
    <item>
      <title>机器学习入门指南</title>
      <link>https://sunlongyu.github.io/blogs/machine-learning-intro/</link>
      <pubDate>Sun, 15 Dec 2024 11:00:00 +0800</pubDate>
      <guid>https://sunlongyu.github.io/blogs/machine-learning-intro/</guid>
      <description>&lt;h1 id=&#34;机器学习入门指南&#34;&gt;机器学习入门指南&lt;/h1&gt;&#xA;&lt;h2 id=&#34;什么是机器学习&#34;&gt;什么是机器学习？&lt;/h2&gt;&#xA;&lt;p&gt;机器学习是人工智能的一个分支，它使计算机能够在没有明确编程的情况下学习和改进。通过算法和统计模型，机器学习系统可以从数据中学习模式并做出预测。&lt;/p&gt;&#xA;&lt;h2 id=&#34;机器学习的类型&#34;&gt;机器学习的类型&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-监督学习-supervised-learning&#34;&gt;1. 监督学习 (Supervised Learning)&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：使用标记的训练数据来学习输入和输出之间的映射&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;应用&lt;/strong&gt;：分类、回归&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;例子&lt;/strong&gt;：邮件垃圾分类、房价预测&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-无监督学习-unsupervised-learning&#34;&gt;2. 无监督学习 (Unsupervised Learning)&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：从未标记的数据中发现隐藏的模式&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;应用&lt;/strong&gt;：聚类、降维&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;例子&lt;/strong&gt;：客户分群、异常检测&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-强化学习-reinforcement-learning&#34;&gt;3. 强化学习 (Reinforcement Learning)&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：通过与环境交互来学习最优行为&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;应用&lt;/strong&gt;：游戏AI、自动驾驶&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;例子&lt;/strong&gt;：AlphaGo、自动驾驶汽车&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;常用算法&#34;&gt;常用算法&lt;/h2&gt;&#xA;&lt;h3 id=&#34;线性回归&#34;&gt;线性回归&lt;/h3&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.linear_model &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; LinearRegression&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 创建示例数据&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]])&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;])&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 训练模型&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; LinearRegression()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(X, y)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 预测&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;prediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict([[&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;]])&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;预测结果: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;prediction&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;决策树&#34;&gt;决策树&lt;/h3&gt;&#xA;&lt;p&gt;决策树是一种直观的算法，通过一系列if-else条件来做决策。&lt;/p&gt;&#xA;&lt;h2 id=&#34;学习路径&#34;&gt;学习路径&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;数学基础&lt;/strong&gt;：线性代数、概率论、统计学&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;编程语言&lt;/strong&gt;：Python或R&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;核心库&lt;/strong&gt;：NumPy、Pandas、Scikit-learn&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;实践项目&lt;/strong&gt;：从简单的数据集开始&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;深度学习&lt;/strong&gt;：TensorFlow或PyTorch&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;实际应用&#34;&gt;实际应用&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;推荐系统&lt;/strong&gt;：Netflix、Amazon的商品推荐&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;图像识别&lt;/strong&gt;：医疗诊断、自动驾驶&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;自然语言处理&lt;/strong&gt;：机器翻译、聊天机器人&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;金融&lt;/strong&gt;：风险评估、算法交易&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;&#xA;&lt;p&gt;机器学习是一个快速发展的领域，具有巨大的应用潜力。从基础概念开始，通过实践项目逐步提高技能，是学习机器学习的最佳方式。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Web开发基础</title>
      <link>https://sunlongyu.github.io/blogs/web-development-basics/</link>
      <pubDate>Sun, 15 Dec 2024 10:00:00 +0800</pubDate>
      <guid>https://sunlongyu.github.io/blogs/web-development-basics/</guid>
      <description>&lt;h1 id=&#34;web开发基础指南&#34;&gt;Web开发基础指南&lt;/h1&gt;&#xA;&lt;h2 id=&#34;什么是web开发&#34;&gt;什么是Web开发？&lt;/h2&gt;&#xA;&lt;p&gt;Web开发是创建和维护网站的过程。它包括网页设计、网页内容开发、客户端/服务器端脚本和网络安全配置等方面。&lt;/p&gt;&#xA;&lt;h2 id=&#34;前端技术栈&#34;&gt;前端技术栈&lt;/h2&gt;&#xA;&lt;h3 id=&#34;html-超文本标记语言&#34;&gt;HTML (超文本标记语言)&lt;/h3&gt;&#xA;&lt;p&gt;HTML是网页的骨架，定义了网页的结构和内容。&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;html&lt;/span&gt;&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;head&lt;/span&gt;&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;title&lt;/span&gt;&amp;gt;我的第一个网页&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;title&lt;/span&gt;&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;head&lt;/span&gt;&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;body&lt;/span&gt;&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;h1&lt;/span&gt;&amp;gt;欢迎来到我的网站&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;h1&lt;/span&gt;&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;p&lt;/span&gt;&amp;gt;这是一个段落。&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;p&lt;/span&gt;&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;body&lt;/span&gt;&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;html&lt;/span&gt;&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;css-层叠样式表&#34;&gt;CSS (层叠样式表)&lt;/h3&gt;&#xA;&lt;p&gt;CSS负责网页的样式和布局。&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-css&#34; data-lang=&#34;css&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;body&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;font-family&lt;/span&gt;: Arial, &lt;span style=&#34;color:#66d9ef&#34;&gt;sans-serif&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;margin&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;padding&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;px&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;h1&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;color&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;#333&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;text-align&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;center&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;javascript&#34;&gt;JavaScript&lt;/h3&gt;&#xA;&lt;p&gt;JavaScript为网页添加交互性和动态功能。&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-javascript&#34; data-lang=&#34;javascript&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;greetUser&lt;/span&gt;() {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;name&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;prompt&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;请输入您的姓名：&amp;#34;&lt;/span&gt;);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;alert&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;你好，&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;name&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;！欢迎访问我们的网站！&amp;#34;&lt;/span&gt;);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;学习路径&#34;&gt;学习路径&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;HTML基础&lt;/strong&gt; - 学习标签、属性和语义化&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;CSS基础&lt;/strong&gt; - 掌握选择器、布局和响应式设计&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;JavaScript基础&lt;/strong&gt; - 理解变量、函数和DOM操作&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;框架学习&lt;/strong&gt; - React、Vue或Angular&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;后端技术&lt;/strong&gt; - Node.js、Python或其他服务器端语言&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;&#xA;&lt;p&gt;Web开发是一个不断发展的领域，需要持续学习和实践。从基础的HTML、CSS和JavaScript开始，逐步深入到更复杂的框架和技术。&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM 微调与对齐</title>
      <link>https://sunlongyu.github.io/blogs/llm-%E5%BE%AE%E8%B0%83%E4%B8%8E%E5%AF%B9%E9%BD%90/</link>
      <pubDate>Thu, 01 Feb 2024 04:55:59 +0530</pubDate>
      <guid>https://sunlongyu.github.io/blogs/llm-%E5%BE%AE%E8%B0%83%E4%B8%8E%E5%AF%B9%E9%BD%90/</guid>
      <description>&lt;h1 id=&#34;一指令微调-instruction-tuning&#34;&gt;一、指令微调 Instruction Tuning&lt;/h1&gt;&#xA;&lt;h2 id=&#34;一指令数据&#34;&gt;（一）指令数据&lt;/h2&gt;&#xA;&lt;p&gt;大模型如同天赋异禀的学生，预训练阶段通过大量阅读积累知识，但缺乏交流和答题能力，此时指令数据便充当“教材和老师”的角色。&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-指令数据组成&#34;&gt;1. 指令数据组成&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;指令 (Instruction / Prompt)&lt;/strong&gt; ：清晰告知模型任务，如 “请回答法国的首都是哪里？”。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;可选的示例 (Demonstration / Example Input)&lt;/strong&gt; ：提供输入样例助模型理解格式，如问题 “巴西的首都是哪里？”。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;输入 (Input)&lt;/strong&gt; ：当前任务的具体输入，如 “中国的首都是哪里？”。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;输出 (Output)&lt;/strong&gt; ：模型应给出的正确答案或完成内容，如 “北京”。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-指令数据构建方法&#34;&gt;2. 指令数据构建方法&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;基于现有 NLP 任务数据集&lt;/strong&gt; ：利用学术界的高质量现成数据集，如机器翻译、文本摘要、文本分类等，为输入 - 输出对配上明确指令（PromptSource 平台是贡献和使用指令模板的平台）。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;基于对话数据构建&lt;/strong&gt; ：收集用户查询，由人类标注员编写高质量回答或从模型生成回答中挑选最佳，组成训练数据。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;基于合成数据构建&lt;/strong&gt; ：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Self-Instruct - “自己出题自己做”&lt;/strong&gt; ：准备少量种子指令，让种子模型生成更多指令及对应的输入和输出，过滤低质样本。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Evol-Instruct - “指令进化论”&lt;/strong&gt; ：通过 “演化提示” 改写已有指令，让模型生成对应输出。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-指令数据构建考虑因素&#34;&gt;3. 指令数据构建考虑因素&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;指令格式&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;指令数量&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;指令数据质量&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;任务多样性&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;二指令微调训练策略&#34;&gt;（二）指令微调训练策略&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-训练参数优化&#34;&gt;1. 训练参数优化&lt;/h3&gt;&#xA;&lt;p&gt;指令微调中的优化器设置、稳定训练技巧和训练技术与预训练阶段多数保持一致，不同之处如下：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;目标函数&lt;/strong&gt; ：作为有监督训练过程，通常采用序列到序列损失，仅计算输出部分损失。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;批次大小和学习率&lt;/strong&gt; ：此阶段使用较小批次大小和学习率对模型进行小幅调整。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;多轮对话高效训练&lt;/strong&gt; ：一次性将多轮对话内容输入模型，通过损失掩码实现仅对每轮对话输出部分计算损失，减少重复前缀计算开销。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-指令数据规划&#34;&gt;2. 指令数据规划&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;平衡数据分布&lt;/strong&gt; ：混合使用多个不同来源、类型的指令数据集。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;多阶段指令数据微调&lt;/strong&gt; ：先用大量通用 NLP 任务指令数据微调打基础，再用少量高质量对话指令数据进一步微调提升能力。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;结合预训练数据与指令微调数据&lt;/strong&gt; ：在指令微调阶段混合预训练数据，保持通用知识和语言建模能力，防止性能退化。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;三参数高效微调--轻量化微调-peft&#34;&gt;（三）参数高效微调 / 轻量化微调 (PEFT)&lt;/h2&gt;&#xA;&lt;p&gt;在微调时冻结大部分预训练模型参数，仅训练少量新增或选择参数，降低成本。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
