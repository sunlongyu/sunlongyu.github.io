<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>RAG on Sun longyu</title>
    <link>https://sunlongyu.github.io/categories/rag/</link>
    <description>Recent content in RAG on Sun longyu</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 15 Dec 2024 12:00:00 +0800</lastBuildDate>
    <atom:link href="https://sunlongyu.github.io/categories/rag/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM开发之RAG</title>
      <link>https://sunlongyu.github.io/blogs/llm%E5%BC%80%E5%8F%91%E4%B9%8Brag/</link>
      <pubDate>Sun, 15 Dec 2024 12:00:00 +0800</pubDate>
      <guid>https://sunlongyu.github.io/blogs/llm%E5%BC%80%E5%8F%91%E4%B9%8Brag/</guid>
      <description>&lt;h1 id=&#34;一rag-概述&#34;&gt;一、RAG 概述&lt;/h1&gt;&#xA;&lt;h2 id=&#34;一llm-的缺陷&#34;&gt;（一）LLM 的缺陷&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;幻觉&lt;/strong&gt; ：LLM 可能生成无事实依据、不与现实世界一致，甚至完全虚构的内容。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;知识更新滞后&lt;/strong&gt; ：LLM 知识的有效性取决于训练数据的时间，存在知识更新滞后问题。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;回答缺乏透明度&lt;/strong&gt; ：LLM 生成的回答通常缺乏引用来源，导致用户难以判断答案的真实性，降低模型可信度。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;二definition&#34;&gt;（二）Definition&lt;/h2&gt;&#xA;&lt;p&gt;为缓解上述问题，RAG 通过检索外部知识库相关信息，并将信息作为上下文输入语言模型，增强生成能力，减少幻觉、提供事实依据，借外部知识库实现实时更新，使生成结果带检索来源，提升专业领域表现。&lt;/p&gt;&#xA;&lt;h2 id=&#34;三组件&#34;&gt;（三）组件&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;向量数据库 (Vector DB)&lt;/strong&gt; ：存储和检索嵌入向量，如 FAISS、Pinecone、Weaviate。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;嵌入模型 (Embedding Model)&lt;/strong&gt; ：将文本转换为向量，如 OpenAI Embeddings、BERT。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;检索模型 (Retriever)&lt;/strong&gt; ：检索相关信息，可使用 BM25、Dense Retrieval (DPR) 等方法。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;LLM (Large Language Model)&lt;/strong&gt; ：如 GPT - 4 等，负责生成最终答案。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;融合策略 (Fusion Strategy)&lt;/strong&gt; ：结合检索信息与 LLM 结果，提高生成可信度。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;四常见应用领域&#34;&gt;（四）常见应用领域&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;企业知识问答&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;法律 / 医疗领域问答&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;金融风控&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;搜索增强对话&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;二rag-实现&#34;&gt;二、RAG 实现&lt;/h1&gt;&#xA;&lt;h2 id=&#34;一数据处理&#34;&gt;（一）数据处理&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-数据清洗-cleaning&#34;&gt;1. 数据清洗 cleaning&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;去重 (Deduplication)&lt;/strong&gt; ：去除重复文档或内容，提高存储效率，减少无效检索。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;噪声过滤 (Noise Filtering)&lt;/strong&gt; ：删除无关内容、广告、低质量文本，避免干扰 LLM 生成。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;格式标准化 (Normalization)&lt;/strong&gt; ：统一文本编码、标点符号、日期格式，保证数据一致性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-数据分片-chunking&#34;&gt;2. 数据分片 chunking&lt;/h3&gt;&#xA;&lt;h4 id=&#34;基于规则的-chunking&#34;&gt;基于规则的 chunking&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;固定长度分片&lt;/strong&gt; ：按固定字符数或单词数切分，如每 512 词分为一个 Chunk。适合结构化文本（如 Wikipedia），但可能导致句子或段落拆散，影响语义完整性。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;基于段落的 Chunking&lt;/strong&gt; ：以自然语言逻辑单元（如句子、段落）进行分片，保持上下文完整性。适用于法律、医学文档，但 Chunk 长度不均匀，可能影响索引效率。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;滑动窗口分片&lt;/strong&gt; ：相邻 Chunk 之间有部分重叠，如窗口大小 256 词，滑动步长 128 词。可保证跨段落上下文信息，减少查询时信息丢失，但增加存储和计算开销。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;基于模型的-chunking&#34;&gt;基于模型的 chunking&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Transformer 句子分割&lt;/strong&gt; ：用 Transformer 模型（如 BERT、RoBERTa）检测句子边界，以高语义相关性进行分片。适用于复杂文档（如法律、医学文本），避免破坏逻辑结构。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;基于依存关系的 Chunking&lt;/strong&gt; ：依存句法分析识别主谓宾结构，以语法结构为基础拆分 Chunk。适用于技术文档（如 API 说明书、论文摘要）。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;基于 LLM 的 Chunking&lt;/strong&gt; ：让 LLM 自适应判断 Chunk 切分点，根据上下文哪些部分应作为独立片段。适用于非结构化文本（如用户评论、社交媒体内容）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;small2big-chunking&#34;&gt;Small2Big Chunking&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;核心思想&lt;/strong&gt; ：先生成较小 Chunk，再按语义相似度合并成较大 Chunk，形成合理文档分片结构，结合固定长度切分与语义分析，避免传统 Chunking 方法弊端。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;初步切分小片段 (Small Chunks)&lt;/strong&gt; ：用固定长度或自然段落切分，保持文本语义完整性。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;计算 Chunk 之间语义相似度&lt;/strong&gt; ：用 BERT/SBERT 向量嵌入将 Chunk 表示为向量；计算相邻 Chunk 余弦相似度 S_{i,i+1}；设相似度阈值 \tau ，若 S_{i,i+1} &amp;gt; \tau 则合并。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;相似度高的 Chunk 合并&lt;/strong&gt; ：形成更大、更有信息密度的片段，逐步执行直至不满足合并条件。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;存入向量数据库&lt;/strong&gt; ：采用 FAISS/Pinecone 存储优化后的 Chunk。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-数据嵌入-embedding&#34;&gt;3. 数据嵌入 embedding&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;嵌入模型选择&lt;/strong&gt; ：&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
